# User Configuration
USER_NAME=YourName  # Your name for the interview assistant (used in prompts and CLI commands)

# API Keys
OPENAI_API_KEY=your_openai_api_key_here
HUGGINGFACE_TOKEN=your_huggingface_token_here  # Required for gated models like Llama

# Model Configuration
MODEL_PROVIDER=local  # Options: local, openai
LOCAL_MODEL_NAME=meta-llama/Llama-3.1-8B-Instruct
DEVICE=mps  # Options: mps, cuda, cpu

# Paths
CAREER_DATA_PATH=./career_data
VECTOR_DB_PATH=./vector_db
MODELS_CACHE_PATH=./models

# Gradio Configuration
GRADIO_SERVER_NAME=0.0.0.0
GRADIO_SERVER_PORT=7860
GRADIO_SHARE=false

# Logging
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR
